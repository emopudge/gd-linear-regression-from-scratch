# Линейная регрессия с градиентным спуском «с нуля»

Этот проект демонстрирует **ручную реализацию линейной регрессии** с использованием **градиентного спуска** без библиотек вроде `sklearn.linear_model`.  
Цель — показать понимание математики и алгоритмов машинного обучения «под капотом».

 **Весь код написан вручную — без Copilot, ChatGPT и автодополнения.**  
Цель — думать головой, а не копировать решения.

---

## Задача
Предсказать медианную стоимость жилья (`MEDV`) в Бостоне на основе признаков (например, среднее число комнат `RM`).

---

## Алгоритм
Используется **градиентный спуск** для минимизации функции потерь MSE:

\[
J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})^2
\]

Обновление параметров:
\[
\theta_j := \theta_j - \alpha \cdot \frac{\partial J}{\partial \theta_j}
\]

---

## Реализация

Класс `GDRegressor` поддерживает:
- Обучение (`fit`)
- Предсказание (`predict`)
- Масштабирование признаков (`z_scaler`)
- Расчёт метрик: RMSE, R²
- Подбор гиперпараметров (`find_optimal_params`)
- Визуализацию сходимости

---

## Результаты на Boston Housing
- **RMSE ≤ 6.45**
- **R² ≥ 0.49**
- Результаты совпадают с `sklearn.LinearRegression` (проверено в тестах)

---

## Как запустить

1. Клонируйте репозиторий:
   ```bash
   git clone https://github.com/ваш-ник/gd-linear-regression-from-scratch.git
   cd gd-linear-regression-from-scratch
   ```
2. Установите зависимости
   ```bash
   pip install -r requirements.txt
   ```
3. Выполните тесты:
   ```bash
   python test_linreg.py
   ```

## Использованные технологии
Python 3.9+
NumPy — для матричных операций
Pandas — загрузка данных
Matplotlib — визуализация
Scikit-learn — только для сравнения (не в обучении!)
