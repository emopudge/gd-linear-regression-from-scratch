# Линейная регрессия с градиентным спуском «с нуля»

Этот проект демонстрирует **ручную реализацию линейной регрессии** с использованием **градиентного спуска** без библиотек вроде `sklearn.linear_model`.  
Цель — показать понимание математики и алгоритмов машинного обучения «под капотом».

 **Весь код написан вручную — без Copilot, ChatGPT и автодополнения.**  
Цель — думать головой, а не копировать решения.

---

## Задача
Предсказать медианную стоимость жилья (`MEDV`) в Бостоне на основе признаков (например, среднее число комнат `RM`).

---

## Алгоритм
Используется **градиентный спуск** для минимизации функции потерь MSE. 
MSE (Mean Squared Error - среднеквадратичная ошибка, чем она меньше, тем модель лучше обучена). 


<img width="592" height="152" alt="image" src="https://github.com/user-attachments/assets/d193a3cf-24fa-4124-9d20-0c3a1a2a74fb" />

где 
- m - количество обучающих примеров, 

- x_i - i-й признаковый вектор (строка из Х),

- y_i - истинное значение целевой переменной,

- h(x_i) - предсказание модели,

- множитель 1/2 добавлен для удобства дифференцирования и сокращается при взятии производной.


В коде:
```python
y_pred = X @ self.theta          # h_θ(x) = Xθ
error = y_pred - y               # (h_θ(x) - y)
gradient = (1 / m) * X.T @ error # ∇J = (1/m) * Xᵀ * (Xθ - y)
loss = (1 / (2 * m)) * np.dot(error, error)  # J(θ) = (1/(2m)) * Σ(error²) (функция потерь)
```



Обновление параметров (градиентный спуск):

<img width="327" height="127" alt="image" src="https://github.com/user-attachments/assets/c49ec908-da08-45f2-bdae-fbca486dace2" />

где alpha - скорость обучения модели (learning rate)

в коде:
```python
self.theta -= self.alpha * gradient  # θ := θ - α * ∇J
```
---

## Реализация

Класс `GDRegressor` поддерживает:
- Обучение (`fit`)
- Предсказание (`predict`)
- Масштабирование признаков (`z_scaler`)
- Расчёт метрик: RMSE, R²
- Подбор гиперпараметров (`find_optimal_params`)
- Визуализацию сходимости

---

## Результаты на Boston Housing
- **RMSE ≤ 6.45**
- **R² ≥ 0.49**
- Результаты совпадают с `sklearn.LinearRegression` (проверено в тестах)

---

## Как запустить

1. Клонируйте репозиторий:
   ```bash
   git clone https://github.com/ваш-ник/gd-linear-regression-from-scratch.git
   cd gd-linear-regression-from-scratch
   ```
2. Установите зависимости
   ```bash
   pip install -r requirements.txt
   ```
3. Выполните тесты:
   ```bash
   python test_linreg.py
   ```

## Использованные технологии
Python 3.9+
NumPy — для матричных операций
Pandas — загрузка данных
Matplotlib — визуализация
Scikit-learn — только для сравнения (не в обучении!)
